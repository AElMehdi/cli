= Getting Started with riff

== Installation

=== [[helm]]Helm install of riff

Riff offers a helm chart for deploying the FaaS and its required services to a Kubernetes Cluster.
The following instructions cover how to initialize helm and install riff.

==== Prerequisites

* A running 1.7+ Kubernetes cluster

TIP: If using Minikube, we recommend using Minikube v0.23.0 or v0.24.1 and avoiding v0.24.0 due to some DNS issues

* Kubernetes CLI `kubectl` installed and on the local system PATH. We recommend using the same version or later as the Kubernetes cluster you are using.

* Docker, if you plan on building samples or your own functions then you will need Docker installed. We have used Docker version 17.x or later.

==== Install Helm

Helm is comprised of 2 components: one is the client (helm) the other is the server component (tiller). The helm client runs on your local machine and can be installed using the instructions found https://github.com/kubernetes/helm/blob/master/README.md#install[here]

Once you have the helm client installed you can install the server component.

For a cluster that does not have RBAC enabled use:

[source, bash]
----
helm init
----

For a cluster that has RBAC enabled use:

[source, bash]
----
kubectl -n kube-system create serviceaccount tiller
kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
helm init --service-account=tiller
----

NOTE: To verify that the tiller pod has started execute the following command: `kubectl get pod --namespace kube-system -l app=helm` and you should see the `tiller` pod running.

===== Add the riff repository to your helm environment

Run the following commands to add the repository:

[source, bash]
----
helm repo add riffrepo https://riff-charts.storage.googleapis.com
helm repo update
----

Run the following command to see that the `riff` chart is available:

[source, bash]
----
helm search riff
----

==== Install riff

===== Using a Kubernetes cluster supporting LoadBalancer

Install the riff helm chart as follows:

For an install with default configuration and no RBAC enabled use:

[source, bash]
----
helm install riffrepo/riff --version 0.0.3 --name demo
----

[NOTE]
====
For a cluster that has RBAC enabled add `--set create.rbac=true`:

[source, bash]
----
helm install riffrepo/riff --version 0.0.3 --name demo --set create.rbac=true
----
====

===== Using a Kubernetes cluster not supporting LoadBalancer (e.g. minikube)

For `NodePort` service types (e.g. running on Minikube) configure the httpGateway to use `NodePort`:

[source, bash]
----
helm install riffrepo/riff --version 0.0.3 --name demo --set httpGateway.service.type=NodePort
----

[NOTE]
====
For a cluster that has RBAC enabled add `--set create.rbac=true`:

[source, bash]
----
helm install riffrepo/riff --version 0.0.3 --name demo --set create.rbac=true --set httpGateway.service.type=NodePort
----
====

===== Verify the installation

You should see a number of resources get created in your cluster. You can see them all using:

[source, bash]
----
kubectl get svc,deployments,pods,functions,topics
----

==== Components installed by the chart

The provided Helm chart installs the following components:

* Kafka and Zookeeper - the message broker used by the riff components

* Topic Controller - the controller that watches the Topic resources and creates new topics in Kafka

* Function Controller - the controller that watches the Function resources and deploys function images together with the sidecar image

* HTTP Gateway - the external facing gateway that listens for data posted to the various topics and forwards the data as a message for the corresponding Kafka topic

==== Customizing the Installation

The Helm chart contains a https://github.com/projectriff/helm-charts/blob/master/riff/values.yaml[values.yaml] file that specifies the default values used when installing the chart. They can all be overridden by using the flag `--set` as described in the documentation for https://docs.helm.sh/helm/#helm-install[Helm Install].

Some values that you might want to override are listed in the https://github.com/projectriff/helm-charts/blob/master/riff/README.md#configuration[Configuration section of the README].

The following are some scenarios for customizing your installation:

NOTE: The same commands work for all of the riff components: `functionController`, `topicController`, and `httpGateway`

* Overriding the version of a riff component:
+
To set the version tag for the `functionController` to `0.0.4-build.1` use the following:
+
[source, bash]
----
helm install riffrepo/riff --name demo --set functionController.image.tag=0.0.4-build.1
----

* Overriding the image repository and version tag of a riff component with a custom built component image:
+
To set the image repository to `mycustom/function-controller` and the version tag to `0.0.4-test.1` for the `functionController`, use the following:
+
[source, bash]
----
helm install riffrepo/riff --name demo --set functionController.image.repository=mycustom/function-controller --set functionController.image.tag=0.0.4-test.1
----

* Overriding the version of the `sidecar` component:
+
The `sidecar` component is only used by the `functionController`, so to set the version for the `sidecar` to `0.0.4-build.1` use the following:
+
[source, bash]
----
helm install riffrepo/riff --name demo --set functionController.sidecar.image.tag=0.0.4-build.1
----

==== Installing locally built snapshot components with Minikube

Clone the https://github.com/projectriff/riff[riff] repository.
The `helm install` commands in this section assume you are in the root directory of that project.

Build the riff components following the link:README.adoc#manual[manual build and deploy] instructions.

To install locally built Docker images with Helm on minikube, use the `values-snapshot.yaml` file, which overrides image tags with snapshot versions:

[source, bash]
----
helm install riffrepo/riff --name demo --values helm/values-snapshot.yaml --set httpGateway.service.type=NodePort
----

==== To tear it all down

[source, bash]
----
helm delete demo --purge
----
